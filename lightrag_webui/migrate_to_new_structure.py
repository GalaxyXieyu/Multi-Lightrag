#!/usr/bin/env python3
"""
å›¾è°±å­˜å‚¨ç»“æ„è¿ç§»è„šæœ¬

å°†ç°æœ‰çš„rag_storageæ•°æ®è¿ç§»åˆ°æ–°çš„graphs/å­ç›®å½•ç»“æ„
"""

import os
import json
import shutil
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List


def count_graph_elements(working_dir: Path) -> tuple[int, int]:
    """ç»Ÿè®¡å›¾è°±ä¸­çš„å®ä½“å’Œå…³ç³»æ•°é‡"""
    try:
        import networkx as nx
        
        if not working_dir.exists():
            return 0, 0
        
        # å°è¯•è¯»å–GraphMLæ–‡ä»¶
        graphml_files = list(working_dir.glob("graph_*.graphml"))
        if graphml_files:
            try:
                graph = nx.read_graphml(graphml_files[0])
                return graph.number_of_nodes(), graph.number_of_edges()
            except Exception as e:
                print(f"è¯»å–GraphMLæ–‡ä»¶å¤±è´¥: {e}")
        
        # å°è¯•ä»å‘é‡æ•°æ®åº“æ–‡ä»¶ç»Ÿè®¡
        entity_count = 0
        relation_count = 0
        
        vdb_entities_file = working_dir / "vdb_entities.json"
        if vdb_entities_file.exists():
            try:
                with open(vdb_entities_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict) and "data" in data:
                        entity_count = len(data["data"])
            except Exception as e:
                print(f"è¯»å–å®ä½“å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
        
        vdb_relations_file = working_dir / "vdb_relationships.json"
        if vdb_relations_file.exists():
            try:
                with open(vdb_relations_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict) and "data" in data:
                        relation_count = len(data["data"])
            except Exception as e:
                print(f"è¯»å–å…³ç³»å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
        
        return entity_count, relation_count
        
    except Exception as e:
        print(f"ç»Ÿè®¡å›¾è°±å…ƒç´ å¤±è´¥: {e}")
        return 0, 0


def migrate_rag_storage_to_graphs():
    """å°†rag_storageè¿ç§»åˆ°graphsç»“æ„"""
    
    # è·¯å¾„é…ç½®
    old_rag_storage = Path("/Volumes/DATABASE/code/LightRAG/rag_storage")
    graphs_dir = Path("/Volumes/DATABASE/code/LightRAG/lightrag_webui/graphs")
    config_file = graphs_dir / "graphs_config.json"
    
    print("ğŸš€ å¼€å§‹è¿ç§»å›¾è°±å­˜å‚¨ç»“æ„...")
    print(f"æºç›®å½•: {old_rag_storage}")
    print(f"ç›®æ ‡ç›®å½•: {graphs_dir}")
    
    # æ£€æŸ¥æºç›®å½•
    if not old_rag_storage.exists():
        print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {old_rag_storage}")
        return False
    
    # åˆ›å»ºgraphsç›®å½•
    graphs_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½ç°æœ‰é…ç½®
    config = {}
    if config_file.exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    
    # éœ€è¦è¿ç§»çš„æ–‡ä»¶
    files_to_migrate = [
        "graph_chunk_entity_relation.graphml",
        "kv_store_doc_status.json",
        "kv_store_full_docs.json",
        "kv_store_llm_response_cache.json",
        "kv_store_text_chunks.json",
        "vdb_chunks.json",
        "vdb_entities.json",
        "vdb_relationships.json"
    ]
    
    # æ£€æŸ¥å“ªäº›æ–‡ä»¶å­˜åœ¨
    existing_files = []
    for file_name in files_to_migrate:
        source_file = old_rag_storage / file_name
        if source_file.exists():
            existing_files.append(file_name)
    
    if not existing_files:
        print("âŒ æºç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„æ–‡ä»¶")
        return False
    
    print(f"ğŸ“ æ‰¾åˆ° {len(existing_files)} ä¸ªæ–‡ä»¶éœ€è¦è¿ç§»:")
    for file_name in existing_files:
        print(f"  - {file_name}")
    
    # ç¡®å®šä¸»å›¾è°±åç§°
    main_graph_id = "ä¸»å›¾è°±"
    main_graph_name = "ä¸»å›¾è°±"
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸»å›¾è°±
    if main_graph_id in config:
        print(f"âš ï¸  å›¾è°± '{main_graph_id}' å·²å­˜åœ¨ï¼Œå°†æ›´æ–°å…¶æ•°æ®")
    else:
        print(f"ğŸ“ åˆ›å»ºæ–°å›¾è°±: {main_graph_name}")
    
    # åˆ›å»ºä¸»å›¾è°±ç›®å½•
    main_graph_dir = graphs_dir / main_graph_id
    main_graph_dir.mkdir(parents=True, exist_ok=True)
    
    # è¿ç§»æ–‡ä»¶
    migrated_files = []
    for file_name in existing_files:
        source_file = old_rag_storage / file_name
        target_file = main_graph_dir / file_name
        
        try:
            if target_file.exists():
                # å¤‡ä»½ç°æœ‰æ–‡ä»¶
                backup_file = main_graph_dir / f"{file_name}.backup"
                shutil.copy2(target_file, backup_file)
                print(f"ğŸ“¦ å¤‡ä»½: {file_name} -> {backup_file.name}")
            
            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(source_file, target_file)
            migrated_files.append(file_name)
            print(f"âœ… è¿ç§»: {file_name}")
            
        except Exception as e:
            print(f"âŒ è¿ç§»å¤±è´¥ {file_name}: {e}")
    
    # ç»Ÿè®¡å›¾è°±æ•°æ®
    entity_count, relation_count = count_graph_elements(main_graph_dir)
    
    # æ›´æ–°é…ç½®
    now = datetime.now().isoformat()
    
    # å…ˆå°†æ‰€æœ‰ç°æœ‰å›¾è°±è®¾ä¸ºéæ´»è·ƒ
    for graph_id in config:
        config[graph_id]["is_active"] = False
    
    # æ·»åŠ æˆ–æ›´æ–°ä¸»å›¾è°±é…ç½®
    config[main_graph_id] = {
        "graph_id": main_graph_id,
        "name": main_graph_name,
        "description": "ä»åŸå§‹rag_storageè¿ç§»çš„ä¸»å›¾è°±",
        "created_at": config.get(main_graph_id, {}).get("created_at", now),
        "updated_at": now,
        "working_dir": str(main_graph_dir),
        "status": "active",
        "is_active": True,  # è®¾ä¸ºæ´»è·ƒå›¾è°±
        "entity_count": entity_count,
        "relation_count": relation_count,
        "document_count": 0,
        "metadata": {
            "migrated_from": str(old_rag_storage),
            "migration_date": now,
            "migrated_files": migrated_files
        }
    }
    
    # ä¿å­˜é…ç½®
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ‰ è¿ç§»å®Œæˆ!")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  - è¿ç§»æ–‡ä»¶æ•°: {len(migrated_files)}")
    print(f"  - å®ä½“æ•°é‡: {entity_count}")
    print(f"  - å…³ç³»æ•°é‡: {relation_count}")
    print(f"  - é…ç½®æ–‡ä»¶: {config_file}")
    print(f"  - ä¸»å›¾è°±ç›®å½•: {main_graph_dir}")
    
    # è¯¢é—®æ˜¯å¦å¤‡ä»½åŸç›®å½•
    print(f"\nğŸ’¡ å»ºè®®:")
    print(f"1. éªŒè¯è¿ç§»ç»“æœæ­£ç¡®åï¼Œå¯ä»¥å¤‡ä»½åŸç›®å½•: {old_rag_storage}")
    print(f"2. é‡å¯LightRAGæœåŠ¡ä»¥ä½¿ç”¨æ–°çš„å›¾è°±ç»“æ„")
    
    return True


def clean_empty_graphs():
    """æ¸…ç†ç©ºçš„å›¾è°±ç›®å½•"""
    graphs_dir = Path("/Volumes/DATABASE/code/LightRAG/lightrag_webui/graphs")
    config_file = graphs_dir / "graphs_config.json"
    
    if not config_file.exists():
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    empty_graphs = []
    
    for graph_id, graph_info in config.items():
        working_dir = Path(graph_info.get("working_dir", ""))
        if working_dir.exists():
            # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„å­˜å‚¨æ–‡ä»¶
            storage_files = list(working_dir.glob("*.json")) + list(working_dir.glob("*.graphml"))
            if not storage_files:
                empty_graphs.append(graph_id)
    
    if empty_graphs:
        print(f"ğŸ—‘ï¸  å‘ç° {len(empty_graphs)} ä¸ªç©ºå›¾è°±:")
        for graph_id in empty_graphs:
            print(f"  - {graph_id}")
        
        response = input("æ˜¯å¦åˆ é™¤è¿™äº›ç©ºå›¾è°±? (y/N): ")
        if response.lower() == 'y':
            for graph_id in empty_graphs:
                working_dir = Path(config[graph_id]["working_dir"])
                if working_dir.exists():
                    shutil.rmtree(working_dir)
                del config[graph_id]
                print(f"âœ… åˆ é™¤ç©ºå›¾è°±: {graph_id}")
            
            # ä¿å­˜æ›´æ–°çš„é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            
            print("ğŸ‰ æ¸…ç†å®Œæˆ!")
    else:
        print("âœ… æ²¡æœ‰å‘ç°ç©ºå›¾è°±")


def main():
    parser = argparse.ArgumentParser(description="å›¾è°±å­˜å‚¨ç»“æ„è¿ç§»å·¥å…·")
    parser.add_argument("action", choices=["migrate", "clean"], 
                       help="æ‰§è¡Œçš„æ“ä½œ: migrate=è¿ç§»æ•°æ®, clean=æ¸…ç†ç©ºå›¾è°±")
    
    args = parser.parse_args()
    
    if args.action == "migrate":
        migrate_rag_storage_to_graphs()
    elif args.action == "clean":
        clean_empty_graphs()


if __name__ == "__main__":
    main()
